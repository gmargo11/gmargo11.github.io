<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.7">Jekyll</generator><link href="https://gmargo11.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://gmargo11.github.io/" rel="alternate" type="text/html" /><updated>2021-07-18T21:49:21-04:00</updated><id>https://gmargo11.github.io/feed.xml</id><title type="html">Gabriel Margolis</title><entry><title type="html">Bagelsaurus</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Bagelsaurus" /><published>2020-12-19T06:59:00-05:00</published><updated>2020-12-19T06:59:00-05:00</updated><id>https://gmargo11.github.io/bagelsaurus</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;Bagelsaurus is located in Cambridge, right on Mass Ave near Porter Square. The line for this bagel shop typically spills well down the block on weekends, and it’s clear why. These bagels are on the smaller and lighter side, but the crisp outside and chewy interior of the plain bagel deliver big texture. The everything bagel retains this crust structure nicely, and accommodates a well-apportioned layer of seasoning. Cream cheese is generously spread and embodies a nice balance of fluff and cream. An overall great bagel. &lt;strong&gt;Score: 9.1&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><category term="bagels" /><summary type="html">Bagelsaurus is located in Cambridge, right on Mass Ave near Porter Square. The line for this bagel shop typically spills well down the block on weekends, and it’s clear why. These bagels are on the smaller and lighter side, but the crisp outside and chewy interior of the plain bagel deliver big texture. The everything bagel retains this crust structure nicely, and accommodates a well-apportioned layer of seasoning. Cream cheese is generously spread and embodies a nice balance of fluff and cream. An overall great bagel. Score: 9.1</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/bagels/bagelsaurus.jpg" /><media:content medium="image" url="https://gmargo11.github.io/images/bagels/bagelsaurus.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Rosenfeld Bagel Co</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Rosenfeld Bagel Co" /><published>2020-12-19T06:58:00-05:00</published><updated>2020-12-19T06:58:00-05:00</updated><id>https://gmargo11.github.io/rosenfeld-bagel-co</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;Rosenfeld Bagel Co serves up a thick NY-style bagel just outside the city in Newton, MA. It’s some of the best New York style you’ll find in greater Boston. Step through the door into a cozy space with overflowing bagel bins front and center. The plain bagel is New York thick and doughy, and the crust has a middling chew. The everything bagel seems to have a slightly stronger exterior crisp, but toppings are applied fairly sparsely to the upper and lower halves. Cream cheese is of the classic style, laid on thick and dense. This is closer to a New York bagel than most you’ll find in Boston, and its great atmosphere is accompanied by a solid bite. &lt;strong&gt;Score: 7.2&lt;/strong&gt;&lt;/p&gt;</content><author><name></name></author><category term="bagels" /><summary type="html">Rosenfeld Bagel Co serves up a thick NY-style bagel just outside the city in Newton, MA. It’s some of the best New York style you’ll find in greater Boston. Step through the door into a cozy space with overflowing bagel bins front and center. The plain bagel is New York thick and doughy, and the crust has a middling chew. The everything bagel seems to have a slightly stronger exterior crisp, but toppings are applied fairly sparsely to the upper and lower halves. Cream cheese is of the classic style, laid on thick and dense. This is closer to a New York bagel than most you’ll find in Boston, and its great atmosphere is accompanied by a solid bite. Score: 7.2</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/bagels/rosenfeld.jpg" /><media:content medium="image" url="https://gmargo11.github.io/images/bagels/rosenfeld.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Visual Intelligence for Quadruped Robots</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Visual Intelligence for Quadruped Robots" /><published>2020-11-30T07:00:00-05:00</published><updated>2020-11-30T07:00:00-05:00</updated><id>https://gmargo11.github.io/cheetah</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;Since Spring 2020, I’ve been working on enabling visual intelligence for the &lt;a href=&quot;https://www.youtube.com/watch?v=G6fMV1UPzkg&quot;&gt;MIT Mini Cheetah&lt;/a&gt;. With this work, supervised by Pulkit Agrawal in collaboration with Sangbae Kim’s &lt;a href=&quot;https://biomimetics.mit.edu/&quot;&gt;Biomimetic Robotics Laboratory&lt;/a&gt;, we aim to unlock the potential of legged robots to robustly navigate highly discontinuous terrains without extensive pre-mapping or offline trajectory optimization. Our approach combines robot learning with proven model-based control architectures, and our development process has involved extensive integration of control, sensing, hardware, simulation, and testbed components.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">Since Spring 2020, I’ve been working on enabling visual intelligence for the MIT Mini Cheetah. With this work, supervised by Pulkit Agrawal in collaboration with Sangbae Kim’s Biomimetic Robotics Laboratory, we aim to unlock the potential of legged robots to robustly navigate highly discontinuous terrains without extensive pre-mapping or offline trajectory optimization. Our approach combines robot learning with proven model-based control architectures, and our development process has involved extensive integration of control, sensing, hardware, simulation, and testbed components.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/cheetah.jpg" /><media:content medium="image" url="https://gmargo11.github.io/images/cheetah.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">General Motors - Autonomous Driving</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="General Motors - Autonomous Driving" /><published>2020-11-30T07:00:00-05:00</published><updated>2020-11-30T07:00:00-05:00</updated><id>https://gmargo11.github.io/gm</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;In Summer 2019, I spent three months at GM’s &lt;a href=&quot;https://www.gm.com/our-company/us/techcenter.html&quot;&gt;Global Technical Center&lt;/a&gt; in Warren, Michigan. I was a member of the Advanced Engineering group’s Autonomous Driving Advanced Sensing team, led by Jon Gerlach. While there, I developed a sensor alignment and validation software tool which eliminated hours of manual labor each time a car’s sensor suite was modified. I also met with suppliers and analyzed emerging sensing technologies, including event-based cameras.&lt;/p&gt;</content><author><name></name></author><category term="project" /><summary type="html">In Summer 2019, I spent three months at GM’s Global Technical Center in Warren, Michigan. I was a member of the Advanced Engineering group’s Autonomous Driving Advanced Sensing team, led by Jon Gerlach. While there, I developed a sensor alignment and validation software tool which eliminated hours of manual labor each time a car’s sensor suite was modified. I also met with suppliers and analyzed emerging sensing technologies, including event-based cameras.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/gmtechcenter.jpg" /><media:content medium="image" url="https://gmargo11.github.io/images/gmtechcenter.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">6.141 Robotics: Science and Systems</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="6.141 Robotics: Science and Systems" /><published>2020-11-30T07:00:00-05:00</published><updated>2020-11-30T07:00:00-05:00</updated><id>https://gmargo11.github.io/rss</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;In Spring 2021, I’ll be a Graduate Teaching Assistant to Luca Carlone in MIT’s premier hands-on robotics course (returning for my third year of involvement). Students learn to construct an autonomous driving stack from the ground up, implementing control, path planning, and localization algorithms in ROS and deploying them in simulation as well as on real hardware. The semester culminates with the Grand Challenge: a no-holds-barred autonomous race through the basement of MIT’s &lt;a href=&quot;https://www.csail.mit.edu/about/stata-center&quot;&gt;Stata Center&lt;/a&gt;. This year, our large course staff will support both a socially distanced in-person challenge and an online challenge.&lt;/p&gt;</content><author><name>Gabe Margolis</name></author><category term="teaching" /><summary type="html">In Spring 2021, I’ll be a Graduate Teaching Assistant to Luca Carlone in MIT’s premier hands-on robotics course (returning for my third year of involvement). Students learn to construct an autonomous driving stack from the ground up, implementing control, path planning, and localization algorithms in ROS and deploying them in simulation as well as on real hardware. The semester culminates with the Grand Challenge: a no-holds-barred autonomous race through the basement of MIT’s Stata Center. This year, our large course staff will support both a socially distanced in-person challenge and an online challenge.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/Racecar.png" /><media:content medium="image" url="https://gmargo11.github.io/images/Racecar.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Informative Neural Ensemble Kalman Learning</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Informative Neural Ensemble Kalman Learning" /><published>2020-11-30T06:59:00-05:00</published><updated>2020-11-30T06:59:00-05:00</updated><id>https://gmargo11.github.io/ensemble</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;From Spring 2019 to Winter 2020, I studied connections between optimal control and neural learning under the supervision of Sai Ravela in MIT’s &lt;a href=&quot;https://essg.mit.edu/&quot;&gt;Earth Signals and Systems Group&lt;/a&gt;. We developed a method which quantifies uncertainty in the parameters of a neural network during supervised learning using Ensemble Kalman Filtering, then efficiently learns the structure for a compact neural representation of a dynamical system by maximizing information gain. We presented our paper, avaiable on &lt;a href=&quot;https://arxiv.org/abs/2008.09915&quot;&gt;arXiv&lt;/a&gt;, at the DDDAS 2020 Conference.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">From Spring 2019 to Winter 2020, I studied connections between optimal control and neural learning under the supervision of Sai Ravela in MIT’s Earth Signals and Systems Group. We developed a method which quantifies uncertainty in the parameters of a neural network during supervised learning using Ensemble Kalman Filtering, then efficiently learns the structure for a compact neural representation of a dynamical system by maximizing information gain. We presented our paper, avaiable on arXiv, at the DDDAS 2020 Conference.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/enkf.png" /><media:content medium="image" url="https://gmargo11.github.io/images/enkf.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Model-based Informative Path Planning</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Model-based Informative Path Planning" /><published>2020-11-30T06:58:00-05:00</published><updated>2020-11-30T06:58:00-05:00</updated><id>https://gmargo11.github.io/slocum</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;From Winter 2018 to Spring 2019, I investigated autonomous science on the &lt;a href=&quot;https://www.video.teledynemarine.com/video/35861012/slocum-glider-overview&quot;&gt;Slocum Glider&lt;/a&gt;, supervised by Brian Williams in MIT’s &lt;a href=&quot;http://groups.csail.mit.edu/mers/&quot;&gt;Model-based Embedded and Robotic Systems Group (MERS)&lt;/a&gt;. Our focus was on enabling the long-range underwater vehicle to efficently plan to gather information about the relationships between properties of its environment. The resulting thesis, presentation, and code can be found on &lt;a href=&quot;https://github.com/gmargo11/MIPP&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><category term="research" /><summary type="html">From Winter 2018 to Spring 2019, I investigated autonomous science on the Slocum Glider, supervised by Brian Williams in MIT’s Model-based Embedded and Robotic Systems Group (MERS). Our focus was on enabling the long-range underwater vehicle to efficently plan to gather information about the relationships between properties of its environment. The resulting thesis, presentation, and code can be found on GitHub.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/slocum.jpg" /><media:content medium="image" url="https://gmargo11.github.io/images/slocum.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">16.410 Principles of Autonomy and Decision Making</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="16.410 Principles of Autonomy and Decision Making" /><published>2020-09-15T08:00:00-04:00</published><updated>2020-09-15T08:00:00-04:00</updated><id>https://gmargo11.github.io/padm</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;I am a Graduate Teaching Assistant for Principles of Autonomy and Decision Making, taught by Howie Shrobe, this Fall 2020. In this joint course, populated by undergraduate and graduate computer scientists and aerospace engineers, we introduce our roughly eighty students to planning as state-space search, then take them for a deep dive into algorithms for reasoning efficiently under constraints and uncertainty. Our primary textbook is &lt;a href=&quot;http://aima.cs.berkeley.edu/&quot;&gt;Artificial Intelligence: A Modern Approach&lt;/a&gt; by Russell &amp;amp; Norvig. I hold recitations and office hours, write exams and problem sets, and advise group-based final projects, alongside one other awesome TA.&lt;/p&gt;</content><author><name>Gabe Margolis</name></author><category term="teaching" /><summary type="html">I am a Graduate Teaching Assistant for Principles of Autonomy and Decision Making, taught by Howie Shrobe, this Fall 2020. In this joint course, populated by undergraduate and graduate computer scientists and aerospace engineers, we introduce our roughly eighty students to planning as state-space search, then take them for a deep dive into algorithms for reasoning efficiently under constraints and uncertainty. Our primary textbook is Artificial Intelligence: A Modern Approach by Russell &amp;amp; Norvig. I hold recitations and office hours, write exams and problem sets, and advise group-based final projects, alongside one other awesome TA.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://gmargo11.github.io/images/padm.png" /><media:content medium="image" url="https://gmargo11.github.io/images/padm.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Robust Imaging with Sum of Squares Barrier Verification</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Robust Imaging with Sum of Squares Barrier Verification" /><published>2019-12-21T07:43:00-05:00</published><updated>2019-12-21T07:43:00-05:00</updated><id>https://gmargo11.github.io/SOS</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;In Fall 2019, I enrolled in a new seminar course in the MIT Aerospace Engineering department: 16.S498 Risk-Aware and Robust Nonlinear Planning. This course, taught by Ashkan Jasour, covered the theory and method of nonlinear optimization and its application to safe control of dynamic systems under uncertainty.&lt;/p&gt;

&lt;p&gt;A particular focus of our learning this semester was Sum of Squares (SOS) programming. A SOS program solver takes advantage of the fact that any expression that is the sum of squared polynomials is guaranteed to be nonnegative for all inputs. The solver searches for such SOS polynomials to satisfy a given set of inequality constraints, and this operation can be applied to efficiently optimize a nonconvex, nonlinear objective.&lt;/p&gt;

&lt;p&gt;In previous work, SOS programming has been used to efficiently find a Lyapunov function guaranteeing stable safety of a dynamical system given an obstacle and uncertainty set. I implemented a slight extension of this technique to find Lyapunov functions guaranteeing visibility of a target object amidst a cluttered environment. When found, these functions act as certificates of robust imaging success for a set of proposed motion primitives, which can be evaluated and executed in real-time.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/gmargo11/robust-imaging/blob/master/paper.pdf&quot; title=&quot;Paper&quot;&gt;Paper&lt;/a&gt; | &lt;a href=&quot;https://github.com/gmargo11/robust-imaging&quot; title=&quot;Code&quot;&gt;Code&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">Controlling a drone to robustly image a target by means of nonlinear optimization.</summary></entry><entry><title type="html">Intuitive Psychology with Communication</title><link href="https://gmargo11.github.io/about" rel="alternate" type="text/html" title="Intuitive Psychology with Communication" /><published>2019-12-21T07:43:00-05:00</published><updated>2019-12-21T07:43:00-05:00</updated><id>https://gmargo11.github.io/CoCoSci</id><content type="html" xml:base="https://gmargo11.github.io/about">&lt;p&gt;&lt;img align=&quot;right&quot; width=&quot;250&quot; src=&quot;/img/interaction-map.JPG&quot; style=&quot;padding: 0 35px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/gmargo11/intuitive-interaction/blob/master/paper.pdf&quot; title=&quot;Paper&quot;&gt;Paper&lt;/a&gt; | &lt;a href=&quot;https://github.com/gmargo11/intuitive-interaction/&quot; title=&quot;Code&quot;&gt;Code&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="jekyll" /><category term="update" /><summary type="html">Modeling how humans infer social behaviors from the observed action of others.</summary></entry></feed>